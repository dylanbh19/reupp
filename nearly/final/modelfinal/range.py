#!/usr/bin/env python
# mail_input_range_forecast.py
# =========================================================
# INPUT-DRIVEN range forecast model
# Users input: mail_type, volume, date -> get call range
# =========================================================

from pathlib import Path
import json
import logging
import sys
import warnings
from datetime import datetime, timedelta

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import holidays
import joblib

from sklearn.model_selection import TimeSeriesSplit
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import QuantileRegressor, Ridge
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error

warnings.filterwarnings('ignore')

LOG = logging.getLogger("mail_input_forecast")
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | mail_input | %(levelname)s | %(message)s",
    handlers=[logging.StreamHandler(sys.stdout)]
)

CFG = {
    "top_mail_types": [
        "Reject_Ltrs", "Cheque 1099", "Exercise_Converted",
        "SOI_Confirms", "Exch_chks", "ACH_Debit_Enrollment",
        "Transfer", "COA", "NOTC_WITHDRAW", "Repl_Chks"
    ],
    "quantiles": [0.1, 0.25, 0.5, 0.75, 0.9],
    "bootstrap_samples": 30,
    "output_dir": "dist_input_ranges"
}

def _to_date(s):
    return pd.to_datetime(s, errors="coerce").dt.date

def _find_file(candidates):
    for p in candidates:
        path = Path(p)
        if path.exists():
            return path
    raise FileNotFoundError(f"None found: {candidates}")

def load_mail_call_data():
    """Load data and create mail->calls relationship dataset"""
    
    # Load mail
    mail_path = _find_file(["mail.csv", "data/mail.csv"])
    mail = pd.read_csv(mail_path)
    mail.columns = [c.lower().strip() for c in mail.columns]
    mail["mail_date"] = _to_date(mail["mail_date"])
    mail = mail.dropna(subset=["mail_date"])

    # Load calls
    vol_path = _find_file(["callvolumes.csv", "data/callvolumes.csv"])
    intent_path = _find_file(["callintent.csv", "data/callintent.csv", "callintetn.csv"])

    # Process volumes
    df_vol = pd.read_csv(vol_path)
    df_vol.columns = [c.lower().strip() for c in df_vol.columns]
    dcol_v = next(c for c in df_vol.columns if "date" in c)
    df_vol[dcol_v] = _to_date(df_vol[dcol_v])
    vol_daily = df_vol.groupby(dcol_v)[df_vol.columns.difference([dcol_v])[0]].sum()

    # Process intent
    df_int = pd.read_csv(intent_path)
    df_int.columns = [c.lower().strip() for c in df_int.columns]
    dcol_i = next(c for c in df_int.columns if "date" in c or "conversationstart" in c)
    df_int[dcol_i] = _to_date(df_int[dcol_i])
    int_daily = df_int.groupby(dcol_i).size()

    # Scale and combine
    overlap = vol_daily.index.intersection(int_daily.index)
    if len(overlap) >= 5:
        scale = int_daily.loc[overlap].mean() / vol_daily.loc[overlap].mean()
        vol_daily *= scale
    calls_total = vol_daily.combine_first(int_daily).sort_index()

    # Aggregate mail daily
    mail_daily = (mail.groupby(["mail_date", "mail_type"], as_index=False)["mail_volume"].sum()
                   .pivot(index="mail_date", columns="mail_type", values="mail_volume").fillna(0))
    
    mail_daily.index = pd.to_datetime(mail_daily.index)
    calls_total.index = pd.to_datetime(calls_total.index)

    # Business days only
    us_holidays = holidays.US()
    biz_mask = (~mail_daily.index.weekday.isin([5, 6])) & (~mail_daily.index.isin(us_holidays))
    mail_daily = mail_daily.loc[biz_mask]
    calls_total = calls_total.loc[calls_total.index.isin(mail_daily.index)]

    daily = mail_daily.join(calls_total.rename("calls_total"), how="inner")
    
    LOG.info("Daily mail-calls data: %s", daily.shape)
    return daily

def create_mail_input_features(daily):
    """Create features for mail input -> calls prediction"""
    
    features_list = []
    targets_list = []
    
    # For each day, create features from THAT day's mail to predict NEXT day's calls
    for i in range(len(daily) - 1):
        current_day = daily.iloc[i]
        next_day = daily.iloc[i + 1]
        
        feature_row = {}
        
        # Mail volumes (INPUT FEATURES)
        available_types = [t for t in CFG["top_mail_types"] if t in daily.columns]
        
        for mail_type in available_types:
            feature_row[f"{mail_type}_volume"] = current_day[mail_type]
        
        # Total mail volume
        total_mail = sum(current_day[t] for t in available_types)
        feature_row["total_mail_volume"] = total_mail
        feature_row["log_total_mail_volume"] = np.log1p(total_mail)
        
        # Mail volume percentiles (relative to historical)
        mail_history = daily[available_types].sum(axis=1).iloc[:i+1]
        if len(mail_history) > 10:
            feature_row["mail_percentile"] = (mail_history <= total_mail).mean()
        else:
            feature_row["mail_percentile"] = 0.5
        
        # Date features
        current_date = daily.index[i]
        feature_row["weekday"] = current_date.weekday()
        feature_row["month"] = current_date.month
        feature_row["is_month_end"] = 1 if current_date.day > 25 else 0
        feature_row["is_holiday_week"] = 1 if current_date in holidays.US() else 0
        
        # Recent call volume context (baseline)
        recent_calls = daily["calls_total"].iloc[max(0, i-5):i+1]
        feature_row["recent_calls_avg"] = recent_calls.mean()
        feature_row["recent_calls_trend"] = recent_calls.diff().mean()
        
        # Target: next day's calls
        target = next_day["calls_total"]
        
        features_list.append(feature_row)
        targets_list.append(target)
    
    # Convert to DataFrames
    X = pd.DataFrame(features_list)
    y = pd.Series(targets_list)
    
    # Clean
    X = X.fillna(0)  # Fill any missing mail types with 0
    
    LOG.info("Mail input features: %d samples x %d features", X.shape[0], X.shape[1])
    LOG.info("Feature columns: %s", list(X.columns))
    
    return X, y

def train_mail_input_models(X, y):
    """Train models that predict calls from mail inputs"""
    
    LOG.info("Training mail input models...")
    
    # Split for validation
    split_point = int(len(X) * 0.8)
    X_train, X_test = X.iloc[:split_point], X.iloc[split_point:]
    y_train, y_test = y.iloc[:split_point], y.iloc[split_point:]
    
    models = {}
    
    # Quantile models for range prediction
    for quantile in CFG["quantiles"]:
        LOG.info("  Training %d%% quantile model...", int(quantile * 100))
        
        model = QuantileRegressor(quantile=quantile, alpha=0.1, solver='highs')
        model.fit(X_train, y_train)
        
        # Validate
        y_pred = model.predict(X_test)
        mae = mean_absolute_error(y_test, y_pred)
        
        models[f"quantile_{quantile}"] = model
        LOG.info("    Validation MAE: %.0f", mae)
    
    # Bootstrap ensemble for uncertainty
    LOG.info("  Training bootstrap ensemble...")
    bootstrap_models = []
    
    for i in range(CFG["bootstrap_samples"]):
        # Bootstrap sample
        sample_idx = np.random.choice(len(X_train), size=len(X_train), replace=True)
        X_boot = X_train.iloc[sample_idx]
        y_boot = y_train.iloc[sample_idx]
        
        # Simple model
        model = RandomForestRegressor(
            n_estimators=50,
            max_depth=6,
            min_samples_leaf=3,
            random_state=i
        )
        model.fit(X_boot, y_boot)
        bootstrap_models.append(model)
    
    models["bootstrap_ensemble"] = bootstrap_models
    
    return models

def predict_from_mail_input(models, mail_inputs, date_str=None):
    """
    Predict call range from mail inputs
    
    mail_inputs: dict like {"Reject_Ltrs": 1000, "Cheque 1099": 500, ...}
    date_str: "2025-01-20" (optional, uses tomorrow if None)
    """
    
    if date_str is None:
        predict_date = datetime.now() + timedelta(days=1)
    else:
        predict_date = datetime.strptime(date_str, "%Y-%m-%d")
    
    # Create feature vector
    feature_row = {}
    
    # Mail volumes
    available_types = [t for t in CFG["top_mail_types"]]
    total_mail = 0
    
    for mail_type in available_types:
        volume = mail_inputs.get(mail_type, 0)
        feature_row[f"{mail_type}_volume"] = volume
        total_mail += volume
    
    feature_row["total_mail_volume"] = total_mail
    feature_row["log_total_mail_volume"] = np.log1p(total_mail)
    feature_row["mail_percentile"] = 0.5  # Default - could improve with historical data
    
    # Date features
    feature_row["weekday"] = predict_date.weekday()
    feature_row["month"] = predict_date.month
    feature_row["is_month_end"] = 1 if predict_date.day > 25 else 0
    feature_row["is_holiday_week"] = 1 if predict_date.date() in holidays.US() else 0
    
    # Baseline features (use defaults)
    feature_row["recent_calls_avg"] = 15000  # Could use actual recent data
    feature_row["recent_calls_trend"] = 0
    
    # Convert to DataFrame
    X_input = pd.DataFrame([feature_row])
    
    # Get quantile predictions
    quantile_preds = {}
    for quantile in CFG["quantiles"]:
        model = models[f"quantile_{quantile}"]
        pred = model.predict(X_input)[0]
        quantile_preds[f"q{int(quantile*100)}"] = max(0, pred)
    
    # Get bootstrap predictions
    bootstrap_preds = []
    for model in models["bootstrap_ensemble"]:
        pred = model.predict(X_input)[0]
        bootstrap_preds.append(max(0, pred))
    
    bootstrap_stats = {
        "mean": np.mean(bootstrap_preds),
        "std": np.std(bootstrap_preds),
        "min": np.min(bootstrap_preds),
        "max": np.max(bootstrap_preds)
    }
    
    return quantile_preds, bootstrap_stats

def create_scenario_interface(models, output_dir):
    """Create simple interface for scenario testing"""
    
    # Test scenarios
    scenarios = [
        {
            "name": "test 1",
            "mail_inputs": {"Reject_Ltrs": 2000, "Cheque 1099": 500},
            "description": "Large batch of reject letters sent"
        },
        {
            "name": "test 2", 
            "mail_inputs": {"Reject_Ltrs": 800, "Cheque 1099": 1200, "Exercise_Converted": 300},
            "description": "Typical mixed mail "
        },
        {
            "name": "test 3",
            "mail_inputs": {"Transfer": 200, "COA": 150},
            "description": "Low volume administrative mail"
        },
        {
            "name": "test 4",
            "mail_inputs": {"Reject_Ltrs": 3000, "Cheque 1099": 2000, "Exercise_Converted": 800},
            "description": " mail volumes high day"
        }
    ]
    
    results = {}
    
    LOG.info("=== SCENARIO TESTING ===")
    
    for scenario in scenarios:
        LOG.info("\nScenario: %s", scenario["name"])
        LOG.info("Description: %s", scenario["description"])
        LOG.info("Mail inputs: %s", scenario["mail_inputs"])
        
        quantile_preds, bootstrap_stats = predict_from_mail_input(
            models, scenario["mail_inputs"]
        )
        
        LOG.info("Predicted call ranges:")
        LOG.info("  Conservative (25-75%%): %.0f - %.0f calls", 
                quantile_preds["q25"], quantile_preds["q75"])
        LOG.info("  Wide range (10-90%%): %.0f - %.0f calls", 
                quantile_preds["q10"], quantile_preds["q90"])
        LOG.info("  Most likely: %.0f calls", quantile_preds["q50"])
        
        results[scenario["name"]] = {
            "mail_inputs": scenario["mail_inputs"],
            "description": scenario["description"],
            "predictions": quantile_preds,
            "bootstrap": bootstrap_stats
        }
    
    # Save scenario results
    with open(output_dir / "scenario_results.json", "w") as f:
        json.dump(results, f, indent=2)
    
    return results

def main():
    output_dir = Path(CFG["output_dir"])
    output_dir.mkdir(exist_ok=True)
    
    LOG.info("=== MAIL INPUT RANGE FORECAST ===")
    
    # Load data
    LOG.info("Loading mail-calls data...")
    daily = load_mail_call_data()
    
    # Create input-output features
    LOG.info("Creating mail input features...")
    X, y = create_mail_input_features(daily)
    
    # Train models
    LOG.info("Training mail input models...")
    models = train_mail_input_models(X, y)
    
    # Save models
    joblib.dump(models, output_dir / "mail_input_models.pkl")
    
    # Test scenarios
    scenario_results = create_scenario_interface(models, output_dir)
    
    # Interactive example
    LOG.info("\n=== INTERACTIVE EXAMPLE ===")
    LOG.info("Example: Predicting calls from specific mail campaign")
    
    # Example input
    example_input = {
        "Reject_Ltrs": 1500,
        "Cheque 1099": 800,
        "Exercise_Converted": 200
    }
    
    LOG.info("Input: %s", example_input)
    
    quantile_preds, bootstrap_stats = predict_from_mail_input(models, example_input)
    
    LOG.info("Output ranges:")
    LOG.info("  Most likely: %.0f calls", quantile_preds["q50"])
    LOG.info("  Business planning (25-75%%): %.0f - %.0f calls", 
            quantile_preds["q25"], quantile_preds["q75"])
    LOG.info("  Capacity planning (10-90%%): %.0f - %.0f calls", 
            quantile_preds["q10"], quantile_preds["q90"])
    
    LOG.info("\nModel ready for stakeholder use!")
    LOG.info("Results saved to: %s", output_dir.resolve())

if __name__ == "__main__":
    main()
